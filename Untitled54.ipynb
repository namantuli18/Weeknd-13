{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled54.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMQ5HbCUga/3S0BebH8JuxZ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/namantuli18/Weeknd-13/blob/master/Untitled54.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1f8HKNxV7eB9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 134
        },
        "outputId": "9f68438e-e1d1-4d2e-86e6-13c716644742"
      },
      "source": [
        "!unzip -x \"/content/CCPP_participants_Data.zip\" "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  /content/CCPP_participants_Data.zip\n",
            "  inflating: sample_submission.csv   \n",
            "  inflating: __MACOSX/._sample_submission.csv  \n",
            "  inflating: Test.csv                \n",
            "  inflating: __MACOSX/._Test.csv     \n",
            "  inflating: Train.csv               \n",
            "  inflating: __MACOSX/._Train.csv    \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FTz-H4fF7rXb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "train=pd.read_csv('Train.csv')\n",
        "test=pd.read_csv('Test.csv')\n",
        "sample=pd.read_csv('sample_submission.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S-x1Zzls761a",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 726
        },
        "outputId": "bf208e34-1c2e-40d8-8f05-f2c963b26f88"
      },
      "source": [
        "!pip install gml"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting gml\n",
            "  Downloading https://files.pythonhosted.org/packages/b0/91/3580e3e1f4151fed64cf37840bae994ea7d1409a58a527b8fd010c31c909/GML-2.0.4-py3-none-any.whl\n",
            "Collecting catboost\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/b2/aa/e61819d04ef2bbee778bf4b3a748db1f3ad23512377e43ecfdc3211437a0/catboost-0.23.2-cp36-none-manylinux1_x86_64.whl (64.8MB)\n",
            "\u001b[K     |████████████████████████████████| 64.8MB 60kB/s \n",
            "\u001b[?25hRequirement already satisfied: scikit-learn in /usr/local/lib/python3.6/dist-packages (from gml) (0.22.2.post1)\n",
            "Requirement already satisfied: lightgbm in /usr/local/lib/python3.6/dist-packages (from gml) (2.2.3)\n",
            "Requirement already satisfied: Keras in /usr/local/lib/python3.6/dist-packages (from gml) (2.3.1)\n",
            "Requirement already satisfied: xgboost in /usr/local/lib/python3.6/dist-packages (from gml) (0.90)\n",
            "Collecting autofeat\n",
            "  Downloading https://files.pythonhosted.org/packages/3a/63/c5aa2e38f50c9dedb1cf1bf6e0b5ab520e2c8747627ca7318a827b618d10/autofeat-1.1.3-py3-none-any.whl\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from catboost->gml) (1.15.0)\n",
            "Requirement already satisfied: pandas>=0.24.0 in /usr/local/lib/python3.6/dist-packages (from catboost->gml) (1.0.5)\n",
            "Requirement already satisfied: numpy>=1.16.0 in /usr/local/lib/python3.6/dist-packages (from catboost->gml) (1.18.5)\n",
            "Requirement already satisfied: plotly in /usr/local/lib/python3.6/dist-packages (from catboost->gml) (4.4.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from catboost->gml) (1.4.1)\n",
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.6/dist-packages (from catboost->gml) (0.10.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (from catboost->gml) (3.2.2)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->gml) (0.16.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from Keras->gml) (3.13)\n",
            "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from Keras->gml) (1.0.8)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from Keras->gml) (1.1.2)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from Keras->gml) (2.10.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.6/dist-packages (from autofeat->gml) (1.1.1)\n",
            "Collecting pint\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/66/a9/18b232462dee45443994b19254cf6fe49893ea81bc7534cb984932d59e38/Pint-0.14-py2.py3-none-any.whl (197kB)\n",
            "\u001b[K     |████████████████████████████████| 204kB 43.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from autofeat->gml) (0.16.0)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.24.0->catboost->gml) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.24.0->catboost->gml) (2.8.1)\n",
            "Requirement already satisfied: retrying>=1.3.3 in /usr/local/lib/python3.6/dist-packages (from plotly->catboost->gml) (1.3.3)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->catboost->gml) (1.2.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib->catboost->gml) (0.10.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->catboost->gml) (2.4.7)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.6/dist-packages (from sympy->autofeat->gml) (1.1.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from pint->autofeat->gml) (49.1.0)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from pint->autofeat->gml) (1.7.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from pint->autofeat->gml) (20.4)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->pint->autofeat->gml) (3.1.0)\n",
            "Installing collected packages: catboost, pint, autofeat, gml\n",
            "Successfully installed autofeat-1.1.3 catboost-0.23.2 gml-2.0.4 pint-0.14\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A6c3TG5a8Hfo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        },
        "outputId": "1d56d80a-e49b-4ff8-ba6f-275601f551c1"
      },
      "source": [
        "!pip install category-encoders"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: category-encoders in /usr/local/lib/python3.6/dist-packages (2.2.2)\n",
            "Requirement already satisfied: patsy>=0.5.1 in /usr/local/lib/python3.6/dist-packages (from category-encoders) (0.5.1)\n",
            "Requirement already satisfied: scipy>=1.0.0 in /usr/local/lib/python3.6/dist-packages (from category-encoders) (1.4.1)\n",
            "Requirement already satisfied: pandas>=0.21.1 in /usr/local/lib/python3.6/dist-packages (from category-encoders) (1.0.5)\n",
            "Requirement already satisfied: scikit-learn>=0.20.0 in /usr/local/lib/python3.6/dist-packages (from category-encoders) (0.22.2.post1)\n",
            "Requirement already satisfied: statsmodels>=0.9.0 in /usr/local/lib/python3.6/dist-packages (from category-encoders) (0.10.2)\n",
            "Requirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.6/dist-packages (from category-encoders) (1.18.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from patsy>=0.5.1->category-encoders) (1.15.0)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.21.1->category-encoders) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.21.1->category-encoders) (2.8.1)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn>=0.20.0->category-encoders) (0.16.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xWzLRywB8Yt0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test['gt']=test['AP']+test['AT']+test['RH']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DxlUhScyqz8a",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        },
        "outputId": "47a9f465-f230-48cb-b31b-861404a639fd"
      },
      "source": [
        "!pip install category-encoders"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting category-encoders\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/44/57/fcef41c248701ee62e8325026b90c432adea35555cbc870aff9cfba23727/category_encoders-2.2.2-py2.py3-none-any.whl (80kB)\n",
            "\r\u001b[K     |████                            | 10kB 20.5MB/s eta 0:00:01\r\u001b[K     |████████▏                       | 20kB 5.7MB/s eta 0:00:01\r\u001b[K     |████████████▏                   | 30kB 7.3MB/s eta 0:00:01\r\u001b[K     |████████████████▎               | 40kB 7.9MB/s eta 0:00:01\r\u001b[K     |████████████████████▎           | 51kB 6.3MB/s eta 0:00:01\r\u001b[K     |████████████████████████▍       | 61kB 6.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▍   | 71kB 7.4MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 81kB 4.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: pandas>=0.21.1 in /usr/local/lib/python3.6/dist-packages (from category-encoders) (1.0.5)\n",
            "Requirement already satisfied: scipy>=1.0.0 in /usr/local/lib/python3.6/dist-packages (from category-encoders) (1.4.1)\n",
            "Requirement already satisfied: patsy>=0.5.1 in /usr/local/lib/python3.6/dist-packages (from category-encoders) (0.5.1)\n",
            "Requirement already satisfied: statsmodels>=0.9.0 in /usr/local/lib/python3.6/dist-packages (from category-encoders) (0.10.2)\n",
            "Requirement already satisfied: scikit-learn>=0.20.0 in /usr/local/lib/python3.6/dist-packages (from category-encoders) (0.22.2.post1)\n",
            "Requirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.6/dist-packages (from category-encoders) (1.18.5)\n",
            "Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.21.1->category-encoders) (2.8.1)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.21.1->category-encoders) (2018.9)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from patsy>=0.5.1->category-encoders) (1.15.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn>=0.20.0->category-encoders) (0.16.0)\n",
            "Installing collected packages: category-encoders\n",
            "Successfully installed category-encoders-2.2.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "baqxVkCE8_en",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 101
        },
        "outputId": "66db4163-7f0d-43bd-dedd-4131727cbf74"
      },
      "source": [
        "from GML.Ghalat_Machine_Learning import Ghalat_Machine_Learning\n",
        "\n",
        "gml = Ghalat_Machine_Learning()\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Welcome to Ghalat Machine Learning!\n",
            "\n",
            "All models are set to train\n",
            "         Have a tea and leave everything on us ;-)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tpVf_0VNX5LM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 774
        },
        "outputId": "2db58206-b901-4040-f541-79b914ddbd8b"
      },
      "source": [
        "new_X,y = gml.Auto_Feature_Engineering(x,y,type_of_task='Regression',test_data=None,\n",
        "                                                          splits=2,fill_na_='median',ratio_drop=0.2,\n",
        "                                                          generate_features=True,feateng_steps=2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "************************************************************ \n",
            "Successfully dealt with missing data!\n",
            "\n",
            "X:\n",
            "\n",
            "           0      1        2      3\n",
            "0     29.07  72.51  1009.24  58.38\n",
            "1     32.38  67.17  1006.97  60.04\n",
            "2     19.29  67.71  1007.94  63.71\n",
            "3     16.45  41.48  1016.64  45.21\n",
            "4     21.43  46.97  1013.94  61.25\n",
            "...     ...    ...      ...    ...\n",
            "9563   4.44  38.44  1016.14  75.35\n",
            "9564  18.18  67.71  1004.50  87.26\n",
            "9565  10.96  45.01  1017.97  95.82\n",
            "9566   8.70  36.24  1013.34  89.50\n",
            "9567  27.97  58.84  1002.25  57.88\n",
            "\n",
            "[9568 rows x 4 columns] \n",
            "Test Data:\n",
            "\n",
            " Empty DataFrame\n",
            "Columns: []\n",
            "Index: [] \n",
            "\n",
            " ************************************************************\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-57-60b417086aad>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m new_X,y = gml.Auto_Feature_Engineering(x,y,type_of_task='Regression',test_data=None,\n\u001b[1;32m      2\u001b[0m                                                           \u001b[0msplits\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfill_na_\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'median'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mratio_drop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m                                                           generate_features=True,feateng_steps=2)\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/GML/Ghalat_Machine_Learning.py\u001b[0m in \u001b[0;36mAuto_Feature_Engineering\u001b[0;34m(self, X, y, type_of_task, test_data, splits, fill_na_, ratio_drop, generate_features, feateng_steps, max_gb)\u001b[0m\n\u001b[1;32m    187\u001b[0m         \u001b[0mcols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtypes\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;34m'object'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    188\u001b[0m         \u001b[0mencoded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 189\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mtr_in\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mval_in\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mStratifiedKFold\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_splits\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msplits\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    190\u001b[0m             \u001b[0mencoder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTargetEncoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcols\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcols\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msmoothing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    191\u001b[0m             \u001b[0mencoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcols\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtr_in\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtr_in\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_split.py\u001b[0m in \u001b[0;36msplit\u001b[0;34m(self, X, y, groups)\u001b[0m\n\u001b[1;32m    333\u001b[0m                 .format(self.n_splits, n_samples))\n\u001b[1;32m    334\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 335\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroups\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    336\u001b[0m             \u001b[0;32myield\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    337\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_split.py\u001b[0m in \u001b[0;36msplit\u001b[0;34m(self, X, y, groups)\u001b[0m\n\u001b[1;32m     78\u001b[0m         \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroups\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindexable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroups\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m         \u001b[0mindices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_num_samples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 80\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mtest_index\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iter_test_masks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroups\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     81\u001b[0m             \u001b[0mtrain_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogical_not\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m             \u001b[0mtest_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtest_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_split.py\u001b[0m in \u001b[0;36m_iter_test_masks\u001b[0;34m(self, X, y, groups)\u001b[0m\n\u001b[1;32m    690\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    691\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_iter_test_masks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroups\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 692\u001b[0;31m         \u001b[0mtest_folds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_test_folds\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    693\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_splits\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    694\u001b[0m             \u001b[0;32myield\u001b[0m \u001b[0mtest_folds\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_split.py\u001b[0m in \u001b[0;36m_make_test_folds\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    661\u001b[0m             raise ValueError(\"n_splits=%d cannot be greater than the\"\n\u001b[1;32m    662\u001b[0m                              \u001b[0;34m\" number of members in each class.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 663\u001b[0;31m                              % (self.n_splits))\n\u001b[0m\u001b[1;32m    664\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_splits\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mmin_groups\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    665\u001b[0m             warnings.warn((\"The least populated class in y has only %d\"\n",
            "\u001b[0;31mValueError\u001b[0m: n_splits=2 cannot be greater than the number of members in each class."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q1IRldNfrfW-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "a8c85d51-0e63-4d9c-b4f6-c3a5c9553879"
      },
      "source": [
        "best_model = gml.GMLRegressor(x,y,neural_net='Yes',epochs=100,models=[MLPRegressor()],verbose=False)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model  LassoLarsCV  got validation loss of  21.668508586941776\n",
            "Model  LinearRegression  got validation loss of  21.668508586941776\n",
            "Model  SVR  got validation loss of  18.66258085800592\n",
            "Model  DecisionTreeRegressor  got validation loss of  14.360759623590647\n",
            "Model  KNeighborsRegressor  got validation loss of  14.778729922801917\n",
            "Model  SGDRegressor  got validation loss of  21.666782290306372\n",
            "Model  RandomForestRegressor  got validation loss of  8.963630249201122\n",
            "Model  AdaBoostRegressor  got validation loss of  8.260187929793355\n",
            "Model  ExtraTreesRegressor  got validation loss of  8.072715037125127\n",
            "[10:32:31] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "Model  XGBRegressor  got validation loss of  13.53261008110895\n",
            "Model  LGBMRegressor  got validation loss of  9.653317702701866\n",
            "Model  CatBoostRegressor  got validation loss of  11.507524367407912\n",
            "Model  GradientBoostingRegressor  got validation loss of  13.066257364332941\n",
            "Model  NaiveBayesianRidge  got validation loss of  21.668361261930475\n",
            "Model  MLPRegressor  got validation accuracy of  30.447922200199738\n",
            "\n",
            " **************************************** \n",
            "Training Neural Network\n",
            " ****************************************\n",
            "Neural Network got validation loss of  19.599729730825352\n",
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_1 (Dense)              (None, 256)               1280      \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 128)               32896     \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 64)                8256      \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 1)                 65        \n",
            "=================================================================\n",
            "Total params: 42,497\n",
            "Trainable params: 42,497\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "\n",
            " ************************************************************ \n",
            "Round One Results\n",
            " ************************************************************ \n",
            "                        Model  Validation_Loss\n",
            "0        ExtraTreesRegressor         8.072715\n",
            "0          AdaBoostRegressor         8.260188\n",
            "0      RandomForestRegressor         8.963630\n",
            "0              LGBMRegressor         9.653318\n",
            "0          CatBoostRegressor        11.507524\n",
            "0  GradientBoostingRegressor        13.066257\n",
            "0               XGBRegressor        13.532610\n",
            "0      DecisionTreeRegressor        14.360760\n",
            "0        KNeighborsRegressor        14.778730\n",
            "0                        SVR        18.662581\n",
            "0             Neural Network        19.599730\n",
            "0               SGDRegressor        21.666782\n",
            "0         NaiveBayesianRidge        21.668361\n",
            "0                LassoLarsCV        21.668509\n",
            "0           LinearRegression        21.668509\n",
            "0               MLPRegressor        30.447922 \n",
            " ************************************************************\n",
            "Model  ExtraTreesRegressor  got validation accuracy of  7.567943013419969\n",
            "Model  AdaBoostRegressor  got validation accuracy of  7.191956172457079\n",
            "Model  RandomForestRegressor  got validation accuracy of  8.049380082906504\n",
            "Model  LGBMRegressor  got validation accuracy of  8.812523777559443\n",
            "Model  CatBoostRegressor  got validation accuracy of  10.33837271029305\n",
            "\n",
            " ************************************************************ \n",
            "Round Two Results\n",
            " ************************************************************ \n",
            "                    Model  Val_Accuracy\n",
            "0      AdaBoostRegressor      7.191956\n",
            "0    ExtraTreesRegressor      7.567943\n",
            "0  RandomForestRegressor      8.049380\n",
            "0          LGBMRegressor      8.812524\n",
            "0      CatBoostRegressor     10.338373 \n",
            " ************************************************************\n",
            "\n",
            "\n",
            " **************************************** \n",
            "Suggested Models for Stacking\n",
            " **************************************** \n",
            " 0        AdaBoostRegressor\n",
            "0      ExtraTreesRegressor\n",
            "0    RandomForestRegressor\n",
            "Name: Model, dtype: object\n",
            "**************************************** \n",
            " PLEASE NOTE: these results are calculated using  <function mean_squared_error at 0x7f84a6107ea0>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "keyMV-iEBEIP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 402
        },
        "outputId": "c5e3be10-b314-42f8-a3e5-80de3b2fa67a"
      },
      "source": [
        "train"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>AT</th>\n",
              "      <th>V</th>\n",
              "      <th>AP</th>\n",
              "      <th>RH</th>\n",
              "      <th>PE</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>29.07</td>\n",
              "      <td>72.51</td>\n",
              "      <td>1009.24</td>\n",
              "      <td>58.38</td>\n",
              "      <td>449.371855</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>32.38</td>\n",
              "      <td>67.17</td>\n",
              "      <td>1006.97</td>\n",
              "      <td>60.04</td>\n",
              "      <td>450.861043</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>19.29</td>\n",
              "      <td>67.71</td>\n",
              "      <td>1007.94</td>\n",
              "      <td>63.71</td>\n",
              "      <td>460.894029</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>16.45</td>\n",
              "      <td>41.48</td>\n",
              "      <td>1016.64</td>\n",
              "      <td>45.21</td>\n",
              "      <td>467.577314</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>21.43</td>\n",
              "      <td>46.97</td>\n",
              "      <td>1013.94</td>\n",
              "      <td>61.25</td>\n",
              "      <td>469.805723</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9563</th>\n",
              "      <td>4.44</td>\n",
              "      <td>38.44</td>\n",
              "      <td>1016.14</td>\n",
              "      <td>75.35</td>\n",
              "      <td>499.615488</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9564</th>\n",
              "      <td>18.18</td>\n",
              "      <td>67.71</td>\n",
              "      <td>1004.50</td>\n",
              "      <td>87.26</td>\n",
              "      <td>461.130122</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9565</th>\n",
              "      <td>10.96</td>\n",
              "      <td>45.01</td>\n",
              "      <td>1017.97</td>\n",
              "      <td>95.82</td>\n",
              "      <td>481.245635</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9566</th>\n",
              "      <td>8.70</td>\n",
              "      <td>36.24</td>\n",
              "      <td>1013.34</td>\n",
              "      <td>89.50</td>\n",
              "      <td>490.928341</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9567</th>\n",
              "      <td>27.97</td>\n",
              "      <td>58.84</td>\n",
              "      <td>1002.25</td>\n",
              "      <td>57.88</td>\n",
              "      <td>457.630310</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>9568 rows × 5 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "         AT      V       AP     RH          PE\n",
              "0     29.07  72.51  1009.24  58.38  449.371855\n",
              "1     32.38  67.17  1006.97  60.04  450.861043\n",
              "2     19.29  67.71  1007.94  63.71  460.894029\n",
              "3     16.45  41.48  1016.64  45.21  467.577314\n",
              "4     21.43  46.97  1013.94  61.25  469.805723\n",
              "...     ...    ...      ...    ...         ...\n",
              "9563   4.44  38.44  1016.14  75.35  499.615488\n",
              "9564  18.18  67.71  1004.50  87.26  461.130122\n",
              "9565  10.96  45.01  1017.97  95.82  481.245635\n",
              "9566   8.70  36.24  1013.34  89.50  490.928341\n",
              "9567  27.97  58.84  1002.25  57.88  457.630310\n",
              "\n",
              "[9568 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m6IvElAtryeh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train['AT_F'] =  9/5 * (train['AT']) + 32\n",
        "test['AT_F'] =  9/5 * (test['AT']) + 32\n",
        "\n",
        "train['AT_K'] =  (train['AT']) + 273\n",
        "test['AT_K'] =  (test['AT']) + 273"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GccSz-TwxgxY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test.drop(['AT_F','AT_K','AT_bins','AVG_AT_bins_PE'],1,inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oOz55CaZr3_n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def at_bins(s):\n",
        "    if s <= 10:\n",
        "        return 1\n",
        "    if s <= 20:\n",
        "        return 2\n",
        "    if s <= 25:\n",
        "        return 3\n",
        "    else:\n",
        "        return 4\n",
        "    \n",
        "train['AT_bins'] = train['AT'].apply(at_bins)\n",
        "test['AT_bins'] = test['AT'].apply(at_bins)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bLQyK3W7r8hM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "r = train.groupby('AT_bins')['PE'].mean()\n",
        "train['AVG_AT_bins_PE'] = train['AT_bins'].map(r)\n",
        "test['AVG_AT_bins_PE'] = test['AT_bins'].map(r)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IlXHzesNezdq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 402
        },
        "outputId": "71493bee-6c8c-449f-fb5b-788fe4bcfd57"
      },
      "source": [
        "train"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>AT</th>\n",
              "      <th>V</th>\n",
              "      <th>AP</th>\n",
              "      <th>RH</th>\n",
              "      <th>PE</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>29.07</td>\n",
              "      <td>72.51</td>\n",
              "      <td>1009.24</td>\n",
              "      <td>58.38</td>\n",
              "      <td>449.371855</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>32.38</td>\n",
              "      <td>67.17</td>\n",
              "      <td>1006.97</td>\n",
              "      <td>60.04</td>\n",
              "      <td>450.861043</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>19.29</td>\n",
              "      <td>67.71</td>\n",
              "      <td>1007.94</td>\n",
              "      <td>63.71</td>\n",
              "      <td>460.894029</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>16.45</td>\n",
              "      <td>41.48</td>\n",
              "      <td>1016.64</td>\n",
              "      <td>45.21</td>\n",
              "      <td>467.577314</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>21.43</td>\n",
              "      <td>46.97</td>\n",
              "      <td>1013.94</td>\n",
              "      <td>61.25</td>\n",
              "      <td>469.805723</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9563</th>\n",
              "      <td>4.44</td>\n",
              "      <td>38.44</td>\n",
              "      <td>1016.14</td>\n",
              "      <td>75.35</td>\n",
              "      <td>499.615488</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9564</th>\n",
              "      <td>18.18</td>\n",
              "      <td>67.71</td>\n",
              "      <td>1004.50</td>\n",
              "      <td>87.26</td>\n",
              "      <td>461.130122</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9565</th>\n",
              "      <td>10.96</td>\n",
              "      <td>45.01</td>\n",
              "      <td>1017.97</td>\n",
              "      <td>95.82</td>\n",
              "      <td>481.245635</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9566</th>\n",
              "      <td>8.70</td>\n",
              "      <td>36.24</td>\n",
              "      <td>1013.34</td>\n",
              "      <td>89.50</td>\n",
              "      <td>490.928341</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9567</th>\n",
              "      <td>27.97</td>\n",
              "      <td>58.84</td>\n",
              "      <td>1002.25</td>\n",
              "      <td>57.88</td>\n",
              "      <td>457.630310</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>9568 rows × 5 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "         AT      V       AP     RH          PE\n",
              "0     29.07  72.51  1009.24  58.38  449.371855\n",
              "1     32.38  67.17  1006.97  60.04  450.861043\n",
              "2     19.29  67.71  1007.94  63.71  460.894029\n",
              "3     16.45  41.48  1016.64  45.21  467.577314\n",
              "4     21.43  46.97  1013.94  61.25  469.805723\n",
              "...     ...    ...      ...    ...         ...\n",
              "9563   4.44  38.44  1016.14  75.35  499.615488\n",
              "9564  18.18  67.71  1004.50  87.26  461.130122\n",
              "9565  10.96  45.01  1017.97  95.82  481.245635\n",
              "9566   8.70  36.24  1013.34  89.50  490.928341\n",
              "9567  27.97  58.84  1002.25  57.88  457.630310\n",
              "\n",
              "[9568 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WxmCyVA95ElX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test['AP']=test['AP']-test['AP'].min()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U3ownio6Yhjd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "col=['AT', 'V', 'AP', 'RH']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lRdfTT1q8NIb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 639
        },
        "outputId": "5ca7e39e-920c-41f0-b041-7fb075e797e9"
      },
      "source": [
        "from sklearn.neural_network import MLPRegressor\n",
        "import numpy as np\n",
        "import tqdm\n",
        "import seaborn as sns\n",
        "import warnings\n",
        "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.ensemble import ExtraTreesRegressor,RandomForestRegressor,AdaBoostRegressor\n",
        "import pandas as pd\n",
        "train=pd.read_csv('Train.csv')\n",
        "test=pd.read_csv('Test.csv')\n",
        "'''train['gt']=train['AP']+train['AT']+train['RH']\n",
        "train['tot']=train['gt']+train['V']'''\n",
        "from xgboost import plot_importance,XGBRegressor\n",
        "sample=pd.read_csv('sample_submission.csv')\n",
        "x=np.array(train[['AT','V','AP','RH']])\n",
        "y=np.array(train['PE'])\n",
        "clf=ExtraTreesRegressor(n_estimators=1000,min_samples_split=.5)\n",
        "clf.fit(x,y)\n",
        "#test.drop(['AP','RH'],1,inplace=True)\n",
        "'''test['gt']=test['AP']+test['AT']+test['RH']\n",
        "test['tot']=test['gt']+test['V']'''\n",
        "l = clf.predict(test)\n",
        "feature_imp = pd.DataFrame(sorted(zip(clf.feature_importances_,col)), columns=['Value','Feature'])\n",
        "\n",
        "plt.figure(figsize=(20, 10))\n",
        "sns.barplot(x=\"Value\", y=\"Feature\", data=feature_imp.sort_values(by=\"Value\", ascending=False))\n",
        "plt.title('LightGBM Features (avg over folds)')\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "plt.savefig('lgbm_importances-01.png')\n",
        "\n",
        "'''\n",
        "for count,rows in tqdm.tqdm(enumerate(test['AT'])):\n",
        "    predict_me=np.array([test['AT'][count],test['V'][count],test['AP'][count],test['RH'][count],\n",
        "                         ])\n",
        "    predict_me=predict_me.reshape(-1,len(predict_me))\n",
        "    writer=clf.predict(predict_me)[0]\n",
        "    sample['PE'][count]=writer'''\n",
        "  \n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1440x720 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"\\nfor count,rows in tqdm.tqdm(enumerate(test['AT'])):\\n    predict_me=np.array([test['AT'][count],test['V'][count],test['AP'][count],test['RH'][count],\\n                         ])\\n    predict_me=predict_me.reshape(-1,len(predict_me))\\n    writer=clf.predict(predict_me)[0]\\n    sample['PE'][count]=writer\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "97u4EipAZAiX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 166
        },
        "outputId": "34782c09-65b8-4e4a-9668-b27ae38d4c9f"
      },
      "source": [
        "feature_imp"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Value</th>\n",
              "      <th>Feature</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.012449</td>\n",
              "      <td>RH</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.030807</td>\n",
              "      <td>AP</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.418723</td>\n",
              "      <td>V</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.538021</td>\n",
              "      <td>AT</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      Value Feature\n",
              "0  0.012449      RH\n",
              "1  0.030807      AP\n",
              "2  0.418723       V\n",
              "3  0.538021      AT"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sZWNCAFlZDwb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test['RH']*=5"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TvkcAWVs0l19",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test.to_csv('sample_submission.csv',index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LPZOb9s-aBhk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 402
        },
        "outputId": "0daf452b-1f0b-413b-82ba-3fbddc441a6a"
      },
      "source": [
        "test"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>AT</th>\n",
              "      <th>V</th>\n",
              "      <th>AP</th>\n",
              "      <th>RH</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>16.98</td>\n",
              "      <td>53.16</td>\n",
              "      <td>1013.95</td>\n",
              "      <td>82.80</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>9.60</td>\n",
              "      <td>41.03</td>\n",
              "      <td>1021.01</td>\n",
              "      <td>69.03</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>6.11</td>\n",
              "      <td>38.68</td>\n",
              "      <td>1017.53</td>\n",
              "      <td>79.23</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>12.34</td>\n",
              "      <td>43.22</td>\n",
              "      <td>1009.28</td>\n",
              "      <td>78.23</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>27.67</td>\n",
              "      <td>59.14</td>\n",
              "      <td>1016.51</td>\n",
              "      <td>61.20</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>38267</th>\n",
              "      <td>14.60</td>\n",
              "      <td>53.82</td>\n",
              "      <td>1016.28</td>\n",
              "      <td>64.83</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>38268</th>\n",
              "      <td>29.67</td>\n",
              "      <td>66.51</td>\n",
              "      <td>1015.60</td>\n",
              "      <td>34.10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>38269</th>\n",
              "      <td>20.13</td>\n",
              "      <td>47.03</td>\n",
              "      <td>1012.59</td>\n",
              "      <td>83.03</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>38270</th>\n",
              "      <td>27.14</td>\n",
              "      <td>70.32</td>\n",
              "      <td>1007.08</td>\n",
              "      <td>73.08</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>38271</th>\n",
              "      <td>18.82</td>\n",
              "      <td>61.27</td>\n",
              "      <td>1019.50</td>\n",
              "      <td>72.23</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>38272 rows × 4 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "          AT      V       AP     RH\n",
              "0      16.98  53.16  1013.95  82.80\n",
              "1       9.60  41.03  1021.01  69.03\n",
              "2       6.11  38.68  1017.53  79.23\n",
              "3      12.34  43.22  1009.28  78.23\n",
              "4      27.67  59.14  1016.51  61.20\n",
              "...      ...    ...      ...    ...\n",
              "38267  14.60  53.82  1016.28  64.83\n",
              "38268  29.67  66.51  1015.60  34.10\n",
              "38269  20.13  47.03  1012.59  83.03\n",
              "38270  27.14  70.32  1007.08  73.08\n",
              "38271  18.82  61.27  1019.50  72.23\n",
              "\n",
              "[38272 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JVia7-9b0I1W",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "5a608c0b-01b3-4b58-d2f8-65fe71ad815c"
      },
      "source": [
        "test['PE']=np.nan\n",
        "\n",
        "for count,rows in tqdm.tqdm(enumerate(l)):\n",
        "    test['PE'][count]=rows\n",
        "\n",
        "test.drop(['AT','V','AP','RH'],1,inplace=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "38272it [00:01, 20234.60it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-_2wyHr8sPtM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 402
        },
        "outputId": "473be95a-5e2a-4cc6-a0a0-4c92dc17dd6d"
      },
      "source": [
        "test"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>PE</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>470.666535</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>484.221658</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>485.901849</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>480.708973</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>454.834926</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>38267</th>\n",
              "      <td>473.148339</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>38268</th>\n",
              "      <td>452.120507</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>38269</th>\n",
              "      <td>468.676698</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>38270</th>\n",
              "      <td>451.440696</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>38271</th>\n",
              "      <td>463.009571</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>38272 rows × 1 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "               PE\n",
              "0      470.666535\n",
              "1      484.221658\n",
              "2      485.901849\n",
              "3      480.708973\n",
              "4      454.834926\n",
              "...           ...\n",
              "38267  473.148339\n",
              "38268  452.120507\n",
              "38269  468.676698\n",
              "38270  451.440696\n",
              "38271  463.009571\n",
              "\n",
              "[38272 rows x 1 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n0ZmbWwkAnBs",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 353
        },
        "outputId": "cce3b97f-2aad-47c1-9da4-6bc80bbe410a"
      },
      "source": [
        "from sklearn.model_selection  import GridSearchCV\n",
        "gsc = GridSearchCV(\n",
        "    estimator=clf,\n",
        "    param_grid={\n",
        "        'n_estimators': range(50,126,25),\n",
        "        'min_samples_leaf': range(20,50,5),\n",
        "        'min_samples_split': range(15,36,5),\n",
        "    },\n",
        "    scoring='r2',\n",
        "    cv=5\n",
        ")\n",
        "gsc.fit(x,y)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GridSearchCV(cv=5, error_score=nan,\n",
              "             estimator=ExtraTreesRegressor(bootstrap=False, ccp_alpha=0.0,\n",
              "                                           criterion='mse', max_depth=None,\n",
              "                                           max_features='auto',\n",
              "                                           max_leaf_nodes=None,\n",
              "                                           max_samples=None,\n",
              "                                           min_impurity_decrease=0.0,\n",
              "                                           min_impurity_split=None,\n",
              "                                           min_samples_leaf=1,\n",
              "                                           min_samples_split=2,\n",
              "                                           min_weight_fraction_leaf=0.0,\n",
              "                                           n_estimators=100, n_jobs=None,\n",
              "                                           oob_score=False, random_state=None,\n",
              "                                           verbose=0, warm_start=False),\n",
              "             iid='deprecated', n_jobs=None,\n",
              "             param_grid={'min_samples_leaf': range(20, 50, 5),\n",
              "                         'min_samples_split': range(15, 36, 5),\n",
              "                         'n_estimators': range(50, 126, 25)},\n",
              "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
              "             scoring='r2', verbose=0)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ltsLCXGLFY5A",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 402
        },
        "outputId": "081d694c-ca55-4e17-8d54-6a987bf4a692"
      },
      "source": [
        "sample"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>PE</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>473.050800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>495.108445</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>496.883244</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>480.787010</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>445.248894</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>92</th>\n",
              "      <td>462.442917</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>93</th>\n",
              "      <td>451.791787</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>94</th>\n",
              "      <td>474.869917</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>95</th>\n",
              "      <td>470.191772</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>96</th>\n",
              "      <td>494.437480</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>97 rows × 1 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "            PE\n",
              "0   473.050800\n",
              "1   495.108445\n",
              "2   496.883244\n",
              "3   480.787010\n",
              "4   445.248894\n",
              "..         ...\n",
              "92  462.442917\n",
              "93  451.791787\n",
              "94  474.869917\n",
              "95  470.191772\n",
              "96  494.437480\n",
              "\n",
              "[97 rows x 1 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gooSQ-4d3j28",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "trainer=pd.read_excel('/content/Folds5x2_pp.xlsx')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cn-0VPon35xn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 402
        },
        "outputId": "733df75e-64cb-4eff-9c65-94fdfbc59333"
      },
      "source": [
        "trainer"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>AT</th>\n",
              "      <th>V</th>\n",
              "      <th>AP</th>\n",
              "      <th>RH</th>\n",
              "      <th>PE</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>14.96</td>\n",
              "      <td>41.76</td>\n",
              "      <td>1024.07</td>\n",
              "      <td>73.17</td>\n",
              "      <td>463.26</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>25.18</td>\n",
              "      <td>62.96</td>\n",
              "      <td>1020.04</td>\n",
              "      <td>59.08</td>\n",
              "      <td>444.37</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>5.11</td>\n",
              "      <td>39.40</td>\n",
              "      <td>1012.16</td>\n",
              "      <td>92.14</td>\n",
              "      <td>488.56</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>20.86</td>\n",
              "      <td>57.32</td>\n",
              "      <td>1010.24</td>\n",
              "      <td>76.64</td>\n",
              "      <td>446.48</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>10.82</td>\n",
              "      <td>37.50</td>\n",
              "      <td>1009.23</td>\n",
              "      <td>96.62</td>\n",
              "      <td>473.90</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9563</th>\n",
              "      <td>16.65</td>\n",
              "      <td>49.69</td>\n",
              "      <td>1014.01</td>\n",
              "      <td>91.00</td>\n",
              "      <td>460.03</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9564</th>\n",
              "      <td>13.19</td>\n",
              "      <td>39.18</td>\n",
              "      <td>1023.67</td>\n",
              "      <td>66.78</td>\n",
              "      <td>469.62</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9565</th>\n",
              "      <td>31.32</td>\n",
              "      <td>74.33</td>\n",
              "      <td>1012.92</td>\n",
              "      <td>36.48</td>\n",
              "      <td>429.57</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9566</th>\n",
              "      <td>24.48</td>\n",
              "      <td>69.45</td>\n",
              "      <td>1013.86</td>\n",
              "      <td>62.39</td>\n",
              "      <td>435.74</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9567</th>\n",
              "      <td>21.60</td>\n",
              "      <td>62.52</td>\n",
              "      <td>1017.23</td>\n",
              "      <td>67.87</td>\n",
              "      <td>453.28</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>9568 rows × 5 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "         AT      V       AP     RH      PE\n",
              "0     14.96  41.76  1024.07  73.17  463.26\n",
              "1     25.18  62.96  1020.04  59.08  444.37\n",
              "2      5.11  39.40  1012.16  92.14  488.56\n",
              "3     20.86  57.32  1010.24  76.64  446.48\n",
              "4     10.82  37.50  1009.23  96.62  473.90\n",
              "...     ...    ...      ...    ...     ...\n",
              "9563  16.65  49.69  1014.01  91.00  460.03\n",
              "9564  13.19  39.18  1023.67  66.78  469.62\n",
              "9565  31.32  74.33  1012.92  36.48  429.57\n",
              "9566  24.48  69.45  1013.86  62.39  435.74\n",
              "9567  21.60  62.52  1017.23  67.87  453.28\n",
              "\n",
              "[9568 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QIh6TEVu4Xpd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "appended_df = pd.concat([trainer,train])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NtJGV0Os4mbJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 402
        },
        "outputId": "7459971b-dc8d-4b70-d633-b50688081d7d"
      },
      "source": [
        "trainer"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>AT</th>\n",
              "      <th>V</th>\n",
              "      <th>AP</th>\n",
              "      <th>RH</th>\n",
              "      <th>PE</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>14.96</td>\n",
              "      <td>41.76</td>\n",
              "      <td>1024.07</td>\n",
              "      <td>73.17</td>\n",
              "      <td>463.26</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>25.18</td>\n",
              "      <td>62.96</td>\n",
              "      <td>1020.04</td>\n",
              "      <td>59.08</td>\n",
              "      <td>444.37</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>5.11</td>\n",
              "      <td>39.40</td>\n",
              "      <td>1012.16</td>\n",
              "      <td>92.14</td>\n",
              "      <td>488.56</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>20.86</td>\n",
              "      <td>57.32</td>\n",
              "      <td>1010.24</td>\n",
              "      <td>76.64</td>\n",
              "      <td>446.48</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>10.82</td>\n",
              "      <td>37.50</td>\n",
              "      <td>1009.23</td>\n",
              "      <td>96.62</td>\n",
              "      <td>473.90</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9563</th>\n",
              "      <td>16.65</td>\n",
              "      <td>49.69</td>\n",
              "      <td>1014.01</td>\n",
              "      <td>91.00</td>\n",
              "      <td>460.03</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9564</th>\n",
              "      <td>13.19</td>\n",
              "      <td>39.18</td>\n",
              "      <td>1023.67</td>\n",
              "      <td>66.78</td>\n",
              "      <td>469.62</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9565</th>\n",
              "      <td>31.32</td>\n",
              "      <td>74.33</td>\n",
              "      <td>1012.92</td>\n",
              "      <td>36.48</td>\n",
              "      <td>429.57</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9566</th>\n",
              "      <td>24.48</td>\n",
              "      <td>69.45</td>\n",
              "      <td>1013.86</td>\n",
              "      <td>62.39</td>\n",
              "      <td>435.74</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9567</th>\n",
              "      <td>21.60</td>\n",
              "      <td>62.52</td>\n",
              "      <td>1017.23</td>\n",
              "      <td>67.87</td>\n",
              "      <td>453.28</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>9568 rows × 5 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "         AT      V       AP     RH      PE\n",
              "0     14.96  41.76  1024.07  73.17  463.26\n",
              "1     25.18  62.96  1020.04  59.08  444.37\n",
              "2      5.11  39.40  1012.16  92.14  488.56\n",
              "3     20.86  57.32  1010.24  76.64  446.48\n",
              "4     10.82  37.50  1009.23  96.62  473.90\n",
              "...     ...    ...      ...    ...     ...\n",
              "9563  16.65  49.69  1014.01  91.00  460.03\n",
              "9564  13.19  39.18  1023.67  66.78  469.62\n",
              "9565  31.32  74.33  1012.92  36.48  429.57\n",
              "9566  24.48  69.45  1013.86  62.39  435.74\n",
              "9567  21.60  62.52  1017.23  67.87  453.28\n",
              "\n",
              "[9568 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zKupb8eQma6m",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 402
        },
        "outputId": "0a47e4d3-a0b2-46ed-b42b-b502abbee07e"
      },
      "source": [
        "test"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>AT</th>\n",
              "      <th>V</th>\n",
              "      <th>AP</th>\n",
              "      <th>RH</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>16.98</td>\n",
              "      <td>53.16</td>\n",
              "      <td>1013.95</td>\n",
              "      <td>82.80</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>9.60</td>\n",
              "      <td>41.03</td>\n",
              "      <td>1021.01</td>\n",
              "      <td>69.03</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>6.11</td>\n",
              "      <td>38.68</td>\n",
              "      <td>1017.53</td>\n",
              "      <td>79.23</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>12.34</td>\n",
              "      <td>43.22</td>\n",
              "      <td>1009.28</td>\n",
              "      <td>78.23</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>27.67</td>\n",
              "      <td>59.14</td>\n",
              "      <td>1016.51</td>\n",
              "      <td>61.20</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>38267</th>\n",
              "      <td>14.60</td>\n",
              "      <td>53.82</td>\n",
              "      <td>1016.28</td>\n",
              "      <td>64.83</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>38268</th>\n",
              "      <td>29.67</td>\n",
              "      <td>66.51</td>\n",
              "      <td>1015.60</td>\n",
              "      <td>34.10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>38269</th>\n",
              "      <td>20.13</td>\n",
              "      <td>47.03</td>\n",
              "      <td>1012.59</td>\n",
              "      <td>83.03</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>38270</th>\n",
              "      <td>27.14</td>\n",
              "      <td>70.32</td>\n",
              "      <td>1007.08</td>\n",
              "      <td>73.08</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>38271</th>\n",
              "      <td>18.82</td>\n",
              "      <td>61.27</td>\n",
              "      <td>1019.50</td>\n",
              "      <td>72.23</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>38272 rows × 4 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "          AT      V       AP     RH\n",
              "0      16.98  53.16  1013.95  82.80\n",
              "1       9.60  41.03  1021.01  69.03\n",
              "2       6.11  38.68  1017.53  79.23\n",
              "3      12.34  43.22  1009.28  78.23\n",
              "4      27.67  59.14  1016.51  61.20\n",
              "...      ...    ...      ...    ...\n",
              "38267  14.60  53.82  1016.28  64.83\n",
              "38268  29.67  66.51  1015.60  34.10\n",
              "38269  20.13  47.03  1012.59  83.03\n",
              "38270  27.14  70.32  1007.08  73.08\n",
              "38271  18.82  61.27  1019.50  72.23\n",
              "\n",
              "[38272 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 52
        }
      ]
    }
  ]
}